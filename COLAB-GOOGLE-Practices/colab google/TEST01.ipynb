{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TEST01.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"yWe_fuaMczjo","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sIVBqnfqik3l","colab_type":"text"},"source":["Ví dụ 1: Sử dụng Linner Regression"]},{"cell_type":"code","metadata":{"id":"nkoE5rjehHIS","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","data = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/data/L1/data_linear.csv\").values\n","N = data.shape[0]\n","x = data[:, 0].reshape(-1, 1)\n","y = data[:, 1].reshape(-1, 1)\n","plt.scatter(x,y)\n","plt.xlabel('mét vuông')\n","plt.ylabel('giá')\n","\n","x = np.hstack((np.ones((N, 1)), x))\n","w = np.array([0.,1.]).reshape(-1,1)\n","\n","numOfIteration = 100\n","cost = np.zeros((numOfIteration,1))\n","\n","learning_rate = 0.000001\n","for i in range(1, numOfIteration):\n","  r = np.dot(x, w) - y\n","  cost[i] = 0.5*np.sum(r*r)\n","  w[0] -= learning_rate*np.sum(r)\n","  # correct the shape dimension\n","  w[1] -= learning_rate*np.sum(np.multiply(r, x[:,1].reshape(-1,1)))\n","  #print(cost[i]) : show value\n","predict = np.dot(x, w)\n","plt.plot((x[0][1], x[N-1][1]),(predict[0], predict[N-1]), 'r')\n","plt.show()\n","\n","x1 = 50\n","y1 = w[0] + w[1] * x1\n","print('Giá nhà cho 50m^2 là : ', y1)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"91VWdTZKjZx9","colab_type":"text"},"source":["Ví dụ 2: Logistic Regression"]},{"cell_type":"code","metadata":{"id":"5wWuH-19jfry","colab_type":"code","colab":{}},"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","# Hàm sigmoid\n","def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","\n","# Load data từ file csv\n","data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/data/L2/dataset.csv').values\n","N, d = data.shape\n","x = data[:, 0:d-1].reshape(-1, d-1)\n","y = data[:, 2].reshape(-1, 1)\n","\n","# Vẽ data bằng scatter\n","plt.scatter(x[:10, 0], x[:10, 1], c='red', edgecolors='none', s=30, label='cho vay')\n","plt.scatter(x[10:, 0], x[10:, 1], c='blue', edgecolors='none', s=30, label='từ chối')\n","plt.legend(loc=1)\n","plt.xlabel('mức lương (triệu)')\n","plt.ylabel('kinh nghiệm (năm)')\n","# Thêm cột 1 vào dữ liệu x\n","x = np.hstack((np.ones((N, 1)), x))\n","w = np.array([0.,0.1,0.1]).reshape(-1,1)\n","# Số lần lặp bước 2\n","numOfIteration = 1000\n","cost = np.zeros((numOfIteration,1))\n","learning_rate = 0.01\n","\n","for i in range(1, numOfIteration):\n","  # Tính giá trị dự đoán\n","  y_predict = sigmoid(np.dot(x, w))\n","  cost[i] = -np.sum(np.multiply(y, np.log(y_predict)) + \\\n","  np.multiply(1-y, np.log(1-y_predict)))\n","  # Gradient descent\n","  w = w - learning_rate * np.dot(x.T, y_predict-y)\n","  #print(cost[i])\n","\n","# Vẽ đường phân cách.\n","t = 0.5\n","plt.plot((4, 10),(-(w[0]+4*w[1]+ np.log(1/t-1))/w[2], -(w[0] + 10*w[1]+ np.log(1/t-1))/w[2]), 'g')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HijdKRiJoNwv","colab_type":"text"},"source":["Ví dụ 3: Neural network (L4)"]},{"cell_type":"code","metadata":{"id":"TjsktwaZoSOq","colab_type":"code","colab":{}},"source":["\n","# Thêm thư viện\n","import numpy as np\n","import pandas as pd\n","\n","# Hàm sigmoid\n","def sigmoid(x):\n","        return 1/(1+np.exp(-x))\n"," \n","   \n","# Đạo hàm hàm sigmoid\n","def sigmoid_derivative(x):\n","        return x*(1-x)\n","\n","\n","# Lớp neural network\n","class NeuralNetwork:\n","    def __init__(self, layers, alpha=0.1):\n","\t\t# Mô hình layer ví dụ [2,2,1]\n","      self.layers = layers \n","      \n","      # Hệ số learning rate\n","      self.alpha = alpha\n","\t\t\n","      # Tham số W, b\n","      self.W = []\n","      self.b = []\n","      \n","      # Khởi tạo các tham số ở mỗi layer\n","      for i in range(0, len(layers)-1):\n","            w_ = np.random.randn(layers[i], layers[i+1])\n","            b_ = np.zeros((layers[i+1], 1))\n","            self.W.append(w_/layers[i])\n","            self.b.append(b_)\n","            \n","    \n","\t# Tóm tắt mô hình neural network\n","    def __repr__(self):\n","        return \"Neural network [{}]\".format(\"-\".join(str(l) for l in self.layers))\n","    \n","\t\n","\t# Train mô hình với dữ liệu\n","    def fit_partial(self, x, y):\n","        A = [x]\n","        \n","        # quá trình feedforward\n","        out = A[-1]\n","        for i in range(0, len(self.layers) - 1):\n","            out = sigmoid(np.dot(out, self.W[i]) + (self.b[i].T))\n","            A.append(out)\n","        \n","        # quá trình backpropagation\n","        y = y.reshape(-1, 1)\n","        dA = [-(y/A[-1] - (1-y)/(1-A[-1]))]\n","        dW = []\n","        db = []\n","        for i in reversed(range(0, len(self.layers)-1)):\n","            dw_ = np.dot((A[i]).T, dA[-1] * sigmoid_derivative(A[i+1]))\n","            db_ = (np.sum(dA[-1] * sigmoid_derivative(A[i+1]), 0)).reshape(-1,1)\n","            dA_ = np.dot(dA[-1] * sigmoid_derivative(A[i+1]), self.W[i].T)\n","            dW.append(dw_)\n","            db.append(db_)\n","            dA.append(dA_)\n","        \n","        # Đảo ngược dW, db\n","        dW = dW[::-1]\n","        db = db[::-1]\n","        \n","\t\t# Gradient descent\n","        for i in range(0, len(self.layers)-1):\n","            self.W[i] = self.W[i] - self.alpha * dW[i]\n","            self.b[i] = self.b[i] - self.alpha * db[i]\n","      \n","    def fit(self, X, y, epochs=20, verbose=10):\n","        for epoch in range(0, epochs):\n","            self.fit_partial(X, y)\n","            if epoch % verbose == 0:\n","                loss = self.calculate_loss(X, y)\n","                print(\"Epoch {}, loss {}\".format(epoch, loss))\n","    \n","\t# Dự đoán\n","    def predict(self, X):\n","        for i in range(0, len(self.layers) - 1):\n","            X = sigmoid(np.dot(X, self.W[i]) + (self.b[i].T))\n","        return X\n","\n","\t# Tính loss function\n","    def calculate_loss(self, X, y):\n","        y_predict = self.predict(X)\n","        #return np.sum((y_predict-y)**2)/2\n","        return -(np.sum(y*np.log(y_predict) + (1-y)*np.log(1-y_predict))) \n","        \n","# Dataset bài 2\n","data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/data/L4/dataset.csv').values\n","N, d = data.shape\n","X = data[:, 0:d-1].reshape(-1, d-1)\n","y = data[:, 2].reshape(-1, 1)\n","\n","p = NeuralNetwork([X.shape[1], 2, 1], 0.1)\n","p.fit(X, y, 10000, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U-b1HyaEoyqU","colab_type":"text"},"source":["Ví dụ: MNIST (thư viện Keras)"]},{"cell_type":"code","metadata":{"id":"MSXQp9Q-o21Z","colab_type":"code","outputId":"d82707c8-4e4d-4569-886f-de08af294bc2","executionInfo":{"status":"ok","timestamp":1574569220381,"user_tz":-420,"elapsed":3799,"user":{"displayName":"Team AILab","photoUrl":"","userId":"18218915572491125522"}},"colab":{"base_uri":"https://localhost:8080/","height":82}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.utils import np_utils\n","from keras.datasets import mnist"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QRB9VmydpBGv","colab_type":"code","colab":{}},"source":["(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","X_val, y_val = X_train[50000:60000,:], y_train[50000:60000]\n","X_train, y_train = X_train[:50000,:], y_train[:50000]\n","print(X_train.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P47AjG8BpD_3","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n","X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MXLeM9nzpFt3","colab_type":"code","colab":{}},"source":["Y_train = np_utils.to_categorical(y_train, 10)\n","Y_val = np_utils.to_categorical(y_val, 10)\n","Y_test = np_utils.to_categorical(y_test, 10)\n","print('Dữ liệu y ban đầu ', y_train[0])\n","print('Dữ liệu y sau one-hot encoding ',Y_train[0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QIJopkX8pOKx","colab_type":"code","colab":{}},"source":["# 5. Định nghĩa model\n","model = Sequential()\n"," \n","# Thêm Convolutional layer với 32 kernel, kích thước kernel 3*3\n","# dùng hàm sigmoid làm activation và chỉ rõ input_shape cho layer đầu tiên\n","model.add(Conv2D(32, (3, 3), activation='sigmoid', input_shape=(28,28,1)))\n","\n","# Thêm Convolutional layer\n","model.add(Conv2D(32, (3, 3), activation='sigmoid'))\n","\n","# Thêm Max pooling layer\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","# Flatten layer chuyển từ tensor sang vector\n","model.add(Flatten())\n","\n","# Thêm Fully Connected layer với 128 nodes và dùng hàm sigmoid\n","model.add(Dense(128, activation='sigmoid'))\n","\n","# Output layer với 10 node và dùng softmax function để chuyển sang xác xuất.\n","model.add(Dense(10, activation='softmax'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z3kDVFgSpSAI","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='adam',\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pLTZptw3pVIX","colab_type":"code","colab":{}},"source":["H = model.fit(X_train, Y_train, validation_data=(X_val, Y_val),\n","          batch_size=32, epochs=10, verbose=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"I2JXZxt-pZvZ","colab_type":"code","colab":{}},"source":["# 8. Vẽ đồ thị loss, accuracy của traning set và validation set\n","fig = plt.figure()\n","numOfEpoch = 10\n","plt.plot(np.arange(0, numOfEpoch), H.history['loss'], label='training loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_loss'], label='validation loss')\n","plt.plot(np.arange(0, numOfEpoch), H.history['acc'], label='accuracy')\n","plt.plot(np.arange(0, numOfEpoch), H.history['val_acc'], label='validation accuracy')\n","plt.title('Accuracy and Loss')\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss|Accuracy')\n","plt.legend()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hxzt8VVAt_Wy","colab_type":"code","colab":{}},"source":["score = model.evaluate(X_test, Y_test, verbose=0)\n","print(score)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8L6lb9R3uDeR","colab_type":"code","colab":{}},"source":["# 10. Dự đoán ảnh\n","plt.imshow(X_test[4].reshape(28,28), cmap='gray')\n","\n","y_predict = model.predict(X_test[4].reshape(1,28,28,1))\n","print('Giá trị dự đoán: ', np.argmax(y_predict))"],"execution_count":0,"outputs":[]}]}